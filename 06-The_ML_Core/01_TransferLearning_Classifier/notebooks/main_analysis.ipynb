{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d44cf6",
   "metadata": {},
   "source": [
    "# Niche Image Classifier: Data Exploration and Transformation\n",
    "\n",
    "This notebook defines the data transformations for the ResNet50 model, which will be trained to classify images of rock, paper, and scissors.\n",
    "\n",
    "**Key Steps:**\n",
    "1.  **Define Transformations:** Create separate transformation pipelines for the training and validation datasets.\n",
    "2.  **Load Datasets:** Use `torchvision.datasets.ImageFolder` to load the images.\n",
    "3.  **Create DataLoaders:** Prepare the data for batching and training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85814ddd",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be93b17",
   "metadata": {},
   "source": [
    "### 2. Define Data Transformations\n",
    "\n",
    "Here, we define two separate transformation pipelines:\n",
    "- **Training (`train_transforms`):** Includes data augmentation (`RandomResizedCrop`, `RandomHorizontalFlip`) to improve model generalization.\n",
    "- **Validation (`val_transforms`):** A simpler pipeline with only resizing and center cropping, as we want to evaluate the model on unmodified images.\n",
    "\n",
    "Both pipelines resize images to `224x224` and normalize them using the ImageNet mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet Mean and Standard Deviation (Required for Transfer Learning with ResNet50)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Define the transformations for the training and validation sets\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "])\n",
    "\n",
    "print(\"Transformations defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48667a13",
   "metadata": {},
   "source": [
    "### 3. Load Datasets with `ImageFolder`\n",
    "\n",
    "Now that the transformations are defined, we can load the datasets from their respective directories. We use `ImageFolder`, which automatically infers class labels from the folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f72f195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['paper', 'rock', 'scissors']\n",
      "Number of training images: 2518\n",
      "Number of validation images: 35\n"
     ]
    }
   ],
   "source": [
    "# Define the data directories\n",
    "# Using an absolute path to avoid issues with the current working directory\n",
    "DATA_DIR = \"/home/kushsoni/Desktop/ai-engineer-roadmap-y1/06-The_ML_Core/01_TransferLearning_Classifier/data/processed\"\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(DATA_DIR, \"val\")\n",
    "\n",
    "# Load the datasets using ImageFolder\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(VAL_DIR, transform=val_transforms)\n",
    "\n",
    "# Print the class names and the number of images in each dataset\n",
    "print(f\"Classes: {train_dataset.classes}\")\n",
    "print(f\"Number of training images: {len(train_dataset)}\")\n",
    "print(f\"Number of validation images: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87be8308",
   "metadata": {},
   "source": [
    "### 4. Create DataLoaders\n",
    "\n",
    "`DataLoader` wraps an iterable around the dataset to enable easy access to the samples. It handles batching, shuffling, and parallel data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d33fa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in train_loader: 79\n",
      "Number of batches in val_loader: 2\n"
     ]
    }
   ],
   "source": [
    "# Define the batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create the DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Verify the number of batches\n",
    "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
    "print(f\"Number of batches in val_loader: {len(val_loader)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_roadmap_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
